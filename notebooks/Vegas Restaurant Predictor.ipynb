{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:97% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set width of Jupyter cell\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:97% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from eli5.sklearn import PermutationImportance\n",
    "import xgboost as xgb\n",
    "import lifelines\n",
    "import pickle\n",
    "\n",
    "import foodie_features\n",
    "import yelp_data_pulling_and_cleaning\n",
    "import build_viva_las_foodie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_row', 200)\n",
    "pd.set_option('display.max_columns', 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_businesses_df = yelp_data_pulling_and_cleaning.pull_raw_business_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = ['Las Vegas']\n",
    "yelp_businesses_df, categories = yelp_data_pulling_and_cleaning.clean_business_data( raw_businesses_df, \\\n",
    "                                                                         type_of_business_list=['Restaurant'], \\\n",
    "                                                                         city_filter_list=cities, \\\n",
    "                                                                         remove_hours=True, \\\n",
    "                                                                         required_num_of_closed_thresh_in_city=1000\n",
    "                                                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_ids = yelp_businesses_df.index.values\n",
    "reviews_df = yelp_data_pulling_and_cleaning.clean_reviews_data(business_ids)\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains, duplicate_locations_df = build_viva_las_foodie.calculate_additional_features(yelp_businesses_df, reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_businesses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['is_chain', 'duplicate_location', 'cost_1', 'cost_2', 'cost_3', 'cost_4', 'is_claimed', 'sentiment', 'avg_review_length', \\\n",
    "            'review_count_before_date', 'rating_before_date' ]\n",
    "data = build_viva_las_foodie.build_X_and_y(yelp_businesses_df, reviews_df, date(2018, 1, 1), forecast_months=[1, 3, 6, 9], \\\n",
    "                                           ignore_distance=False, load_NLP=True, do_distance=False, features=features)\n",
    "X = data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[ [column for column in data if column.startswith('closed_forecast')] ].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_length = '9_months'\n",
    "y = data['closed_forecast_%s'%forecast_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = data.append(pd.read_csv('data_2018_1_1.csv').set_index('business_id'))[features]\n",
    "#y = data.append(pd.read_csv('data_2018_1_1.csv').set_index('business_id'))['closed_forecast_6_months']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA of features\n",
    "num_of_close = y[y == 1].shape[0]\n",
    "num_of_open = y[y == 0].shape[0]\n",
    "print \"Number open(closed) in dataset: %s(%s) \\n\"%(num_of_open, num_of_close)\n",
    "\n",
    "num_cost_1_closed = float(X[ (X.index.isin(y[y == 1].index)) & (X.cost_1 == 1) ].shape[0])\n",
    "num_cost_1_open =  float( X[ (X.index.isin(y[y == 0].index)) & (X.cost_1 == 1)].shape[0])\n",
    "num_cost_1 = float( X[ X.cost_1 == 1 ].shape[0])\n",
    "\n",
    "num_cost_2_closed = float( X[ (X.index.isin(y[y == 1].index)) & (X.cost_2 == 1) ].shape[0])\n",
    "num_cost_2_open = float( X[ (X.index.isin(y[y == 0].index)) & (X.cost_2 == 1)].shape[0])\n",
    "num_cost_2 = float( X[ X.cost_2 == 1 ].shape[0])\n",
    "\n",
    "num_cost_3_closed =  float( X[ (X.index.isin(y[y == 1].index)) & (X.cost_3 == 1) ].shape[0])\n",
    "num_cost_3_open = float( X[ (X.index.isin(y[y == 0].index)) & (X.cost_3 == 1)].shape[0])\n",
    "num_cost_3 = float( X[ X.cost_3 == 1 ].shape[0])\n",
    "\n",
    "num_cost_4_closed = float( X[ (X.index.isin(y[y == 1].index)) & (X.cost_4 == 1) ].shape[0])\n",
    "num_cost_4_open = float( X[ (X.index.isin(y[y == 0].index)) & (X.cost_4 == 1)].shape[0])\n",
    "num_cost_4 = float( X[ X.cost_4 == 1 ].shape[0])\n",
    "\n",
    "avg_cost_closed = (1 * num_cost_1_closed + 2 * num_cost_2_closed + 3 * num_cost_3_closed + 4 * num_cost_4_closed) / num_of_close\n",
    "avg_cost_open = (1 * num_cost_1_open + 2 * num_cost_2_open + 3 * num_cost_3_open + 4 * num_cost_4_open) / num_of_open\n",
    "avg_cost = (1 * num_cost_1 + 2 * num_cost_2 + 3 * num_cost_3 + 4 * num_cost_4) / (num_of_open + num_of_close)\n",
    "\n",
    "print \"Avg cost for closed restaurants: \", avg_cost_closed\n",
    "print \"Avg cost for open resturants: \", avg_cost_open\n",
    "print \"Avg cost for all restaurants:\", avg_cost\n",
    "print \"\\n\"\n",
    "print \"Avg sentiment for closed:\", X[X.index.isin(y[y == 1].index)].sentiment.mean()\n",
    "print \"Avg sentiment for open:\", X[X.index.isin(y[y == 0].index)].sentiment.mean()\n",
    "print \"Avg sentiment total:\", X.sentiment.mean()\n",
    "print \"\\n\"\n",
    "print \"Avg review length for closed:\", X[X.index.isin(y[y == 1].index)].avg_review_length.mean()\n",
    "print \"Avg review length for open:\", X[X.index.isin(y[y == 0].index)].avg_review_length.mean()\n",
    "print \"Avg review length total\", X.avg_review_length.mean()\n",
    "print \"\\n\"\n",
    "print \"Avg rating for closed:\", X[X.index.isin(y[y == 1].index)].rating_before_date.mean()\n",
    "print \"Avg rating for open:\", X[X.index.isin(y[y == 0].index)].rating_before_date.mean()\n",
    "print \"Avg rating total:\", X.rating_before_date.mean()\n",
    "print \"\\n\"\n",
    "print \"Avg review count for closed:\", X[X.index.isin(y[y == 1].index)].review_count_before_date.mean()\n",
    "print \"Avg review count for open:\", X[X.index.isin(y[y == 0].index)].review_count_before_date.mean()\n",
    "print \"Avg review count total:\", X.review_count_before_date.mean()\n",
    "print \"\\n\"\n",
    "print \"Is chain for closed:\", X[ (X.index.isin(y[y == 1].index)) & (X.is_chain == 1) ].shape[0]\n",
    "print \"Is not chain for closed:\", X[ (X.index.isin(y[y == 1].index)) & (X.is_chain == 0)].shape[0]\n",
    "print \"Is chain for open:\", X[ (X.index.isin(y[y == 0].index)) & (X.is_chain == 1) ].shape[0]\n",
    "print \"Is not chain for open:\", X[ (X.index.isin(y[y == 0].index)) & (X.is_chain == 0) ].shape[0]\n",
    "print \"\\n\"\n",
    "print \"Dup loc for closed:\", X[ (X.index.isin(y[y == 1].index)) & (X.duplicate_location == 1) ].shape[0]\n",
    "print \"Not dup loc for closed:\", X[ (X.index.isin(y[y == 1].index)) & (X.duplicate_location == 0)].shape[0] \n",
    "print \"Dup loc for open:\", X[ (X.index.isin(y[y == 0].index)) & (X.duplicate_location == 1) ].shape[0]\n",
    "print \"Not dup loc for open:\", X[ (X.index.isin(y[y == 0].index)) & (X.duplicate_location == 0) ].shape[0]\n",
    "print \"\\n\"\n",
    "print \"Is claimed for closed:\", X[ (X.index.isin(y[y == 1].index)) & (X.is_claimed == 1) ].shape[0]\n",
    "print \"Is not claimed for closed:\", X[ (X.index.isin(y[y == 1].index)) & (X.is_claimed == 0)].shape[0] \n",
    "print \"Is claimed for open:\", X[ (X.index.isin(y[y == 0].index)) & (X.is_claimed == 1) ].shape[0]\n",
    "print \"Is not claimed for open:\", X[ (X.index.isin(y[y == 0].index)) & (X.is_claimed == 0) ].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_df = pd.DataFrame(data= {'Open': [3100, 4155], 'Closed': [132, 473]}, index= ['Yes','No'] )\n",
    "\n",
    "objects = ('Open', 'Closed')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [ 100*float(chain_df.Open.Yes)/(chain_df.Open.Yes + chain_df.Open.No), 100*float(chain_df.Closed.Yes)/(chain_df.Closed.Yes + chain_df.Closed.No) ]\n",
    "\n",
    "barplot = plt.bar(y_pos, performance, align='center')#, alpha=0.5)\n",
    "barplot[0].set_color('cornflowerblue')\n",
    "barplot[1].set_color('salmon')\n",
    "plt.xticks(y_pos, objects)\n",
    "xlocs=[i+1 for i in range(0,2)]\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.tick_params(axis='both', which='minor', labelsize=15)\n",
    "\n",
    "for i, v in enumerate(performance):\n",
    "    plt.text(xlocs[i] - 1.15, v + 1.5, str(round(v,0)),fontsize=20)\n",
    "\n",
    "plt.ylim([0,50])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = ('Open', 'Closed')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [ 478, 504 ]\n",
    "\n",
    "barplot = plt.bar(y_pos, performance, align='center')\n",
    "barplot[0].set_color('cornflowerblue')\n",
    "barplot[1].set_color('salmon')\n",
    "plt.xticks(y_pos, objects)\n",
    "xlocs=[i+1 for i in range(0,2)]\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.tick_params(axis='both', which='minor', labelsize=15)\n",
    "\n",
    "for i, v in enumerate(performance):\n",
    "    plt.text(xlocs[i] - 1.18, v + 15.1, str(round(v,2)),fontsize=20)\n",
    "\n",
    "plt.ylim([0,600])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_columns = []\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.drop(dropped_columns,axis=1).values, y.values, test_size=0.2)\n",
    "X_train_no_val, X_train_val, y_train_no_val, y_train_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(X.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.rcParams.update({'font.size': 17})\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.colorbar()\n",
    "    tick_marks = [0, 1]\n",
    "    plt.xticks(tick_marks, ['Open','Closed'], rotation=45)\n",
    "    plt.yticks(tick_marks, ['Open','Closed'])\n",
    "    plt.tick_params(axis='both', which='major')\n",
    "    plt.tick_params(axis='both', which='minor')\n",
    "    for (j,i),label in np.ndenumerate(cm):\n",
    "        plt.text(i,j,label,ha='center',va='center')\n",
    "        plt.text(i,j,label,ha='center',va='center')\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_logistic = {\n",
    "    'logistic__C': np.logspace(-4, 4, 4),\n",
    "    'logistic__solver' : [ 'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'logistic__max_iter' : [500, 1000, 2000]\n",
    "}\n",
    "param_grid_rf = {\n",
    "    'rf__max_depth' : [4, 6, 8],\n",
    "    'rf__n_estimators' : [500, 1000, 2000]\n",
    "}\n",
    "param_grid_xgb = {\n",
    "    'xgb__min_child_weight': [1, 5, 10],\n",
    "    'xgb__gamma': [0.5, 1, 1.5, 2, 5],\n",
    "    'xgb__subsample': [0.6, 0.8, 1.0],\n",
    "    'xgb__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'xgb__learning_rate': [0.01, 0.02, 0.05, 0.1],\n",
    "    'xgb__max_depth': [3, 4, 5]\n",
    "    }\n",
    "\n",
    "#pipe = Pipeline([ ( 'scaler', StandardScaler() ), ( 'logistic', LogisticRegression(penalty='l2', class_weight='balanced') ) ])\n",
    "#grid_search = GridSearchCV(pipe, param_grid_logistic, cv=5, scoring='roc_auc', n_jobs=-1) #roc_auc\n",
    "\n",
    "#pipe = Pipeline([ ( 'rf', RandomForestClassifier(class_weight='balanced') ) ])\n",
    "#grid_search = GridSearchCV(pipe, param_grid_rf, cv=5, scoring='roc_auc', n_jobs=-1) #roc_auc\n",
    "\n",
    "balanced_class_ratio = float((y_train==0).sum())/(y_train==1).sum()\n",
    "pipe = Pipeline([ ( 'xgb', xgb.XGBClassifier(scale_pos_weight=balanced_class_ratio) ) ])\n",
    "grid_search = GridSearchCV(pipe, param_grid_xgb, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)\n",
    "y_pred_train = grid_search.best_estimator_.predict(X_train)\n",
    "print \"F1 Score:\", f1_score(y_train, y_pred_train)\n",
    "print \"Precision Score:\", precision_score(y_train, y_pred_train)\n",
    "print \"Recall Score:\", recall_score(y_train, y_pred_train)\n",
    "print \"Accuracy Score:\", accuracy_score(y_train, y_pred_train)\n",
    "confusion_matrix(y_true=y_train, y_pred=y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('trained_classifier_%s.pkl'%forecast_length, 'wb') as fid:\n",
    "#    pickle.dump(grid_search.best_estimator_, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('trained_classifier_6_months.pkl', 'rb') as fid:\n",
    "#    gs_model = pickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, grid_search.best_estimator_.predict_proba(X_test)[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "opt_fpr, opt_tpr, opt_threshold = fpr[(tpr + 1 - fpr).argmax()], tpr[(tpr + 1 - fpr).argmax()], thresholds[(tpr + 1 - fpr).argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='AUC = %0.2f' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.plot([opt_fpr],[opt_tpr],'bo', label='Optimal Threshold' %opt_threshold, markersize=15)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve 1-month model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_roc = np.array([1 if grid_search.best_estimator_.predict_proba(X_test)[i,1] > opt_threshold else 0 for i in range(X_test.shape[0]) ])\n",
    "print \"F1 Score:\", f1_score(y_test, y_pred_roc)\n",
    "print \"Precision Score:\", precision_score(y_test, y_pred_roc)\n",
    "print \"Recall Score:\", recall_score(y_test, y_pred_roc)\n",
    "print \"Accuracy Score:\", accuracy_score(y_test, y_pred_roc)\n",
    "plot_confusion_matrix(confusion_matrix(y_true=y_test, y_pred=y_pred_roc), title='%s'%forecast_length.replace('_',' ')[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred_test = grid_search.best_estimator_.predict(X_test)\n",
    "print \"F1 Score:\", f1_score(y_test, y_pred_test)\n",
    "print \"Precision Score:\", precision_score(y_test, y_pred_test)\n",
    "print \"Recall Score:\", recall_score(y_test, y_pred_test)\n",
    "print \"Accuracy Score:\", accuracy_score(y_test, y_pred_test)\n",
    "plot_confusion_matrix(confusion_matrix(y_true=y_test, y_pred=y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate coefficients, feature importances, etc.\n",
    "features_to_names = { 'f{i}'.format(i=i) : X.columns.values[i] for i in range(len(X.columns)) }\n",
    "print features_to_names, '\\n'\n",
    "if 'scaler' in grid_search.best_estimator_.named_steps:\n",
    "    print grid_search.best_estimator_.named_steps['scaler'].mean_\n",
    "    print grid_search.best_estimator_.named_steps['logistic'].coef_\n",
    "elif 'xgb' in grid_search.best_estimator_.named_steps:\n",
    "    print 'gain', sorted(grid_search.best_estimator_.named_steps['xgb'].get_booster().get_score(importance_type='gain').items(), key = lambda x : x[1], reverse=True), '\\n'\n",
    "    print 'weight', sorted(grid_search.best_estimator_.named_steps['xgb'].get_booster().get_score(importance_type='weight').items(), key = lambda x : x[1], reverse=True), '\\n'\n",
    "    print 'cover', sorted(grid_search.best_estimator_.named_steps['xgb'].get_booster().get_score(importance_type='cover').items(), key = lambda x : x[1], reverse=True), '\\n'\n",
    "    print 'total_gain', sorted(grid_search.best_estimator_.named_steps['xgb'].get_booster().get_score(importance_type='total_gain').items(), key = lambda x : x[1], reverse=True), '\\n'\n",
    "    print 'total_cover', sorted(grid_search.best_estimator_.named_steps['xgb'].get_booster().get_score(importance_type='total_cover').items(), key = lambda x : x[1], reverse=True), '\\n'\n",
    "    print 'fscore', sorted(grid_search.best_estimator_.named_steps['xgb'].get_booster().get_fscore().items(), key = lambda x : x[1], reverse=True)\n",
    "elif 'rf' in grid_search.best_estimator_.named_steps:\n",
    "    print grid_search.best_estimator_.named_steps['rf'].feature_importances_\n",
    "else:\n",
    "    print \"Invalid pipeline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#xgb.plot_importance(grid_search.best_estimator_.named_steps['xgb'].get_booster(), importance_type='gain')\n",
    "#xgb.plot_importance(grid_search.best_estimator_.named_steps['xgb'].get_booster(), importance_type='weight')\n",
    "#xgb.plot_importance(grid_search.best_estimator_.named_steps['xgb'].get_booster(), importance_type='cover')\n",
    "xgb.plot_tree(grid_search.best_estimator_.named_steps['xgb'].get_booster())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at 3 and 4 star restaurants, but make sure to separate these because you've trained on some of them\n",
    "#data[ (data.cost_3 == 1) | (data.cost_4 == 1) ][features]\n",
    "\n",
    "#grid_search.best_estimator_.predict(X[ (X.cost_3 == 1) | (X.cost_4 == 1) ].values)\n",
    "#y[ X[ (X.cost_3 == 1) | (X.cost_4 == 1) ].index ].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(data = { 'F1':        [0.08,0.22,0.37,0.44], 'Recall'  : [0.80,0.95,0.88,0.96], \\\n",
    "                                   'Precision': [0.04,0.12,0.24,0.28], 'Accuracy': [0.88,0.82,0.87,0.85] }, \\\n",
    "                          index= [1,3,6,9] )\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(metrics_df.index,100*metrics_df.Recall, '-o')\n",
    "#plt.plot(metrics_df.index,100*metrics_df.Accuracy, '-o')\n",
    "#plt.plot(metrics_df.index,[100*metrics_df.Accuracy.mean() for i in range(metrics_df.Accuracy.shape[0])], '--')\n",
    "#plt.plot(metrics_df.index,100*metrics_df.Precision, '-o')\n",
    "plt.plot(metrics_df.index,100*metrics_df.F1, '-o')\n",
    "plt.xticks(metrics_df.index)\n",
    "plt.xlabel('Months')\n",
    "plt.ylabel('Percentage')\n",
    "#plt.yticks([80, 82, 84, 86, 88, 90])\n",
    "#plt.title('Accuracy across models')\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Pipeline([ ( 'scaler', StandardScaler() ), ( 'lr', LogisticRegression(solver='lbfgs', max_iter=1000, random_state=42, class_weight='balanced') ) ])\n",
    "#model = Pipeline([ ( 'scaler', StandardScaler() ), ( 'lr', RandomForestClassifier(max_depth=5, n_estimators=1000, class_weight='balanced') ) ])\n",
    "model.fit(X_train_no_val, y_train_no_val)\n",
    "y_pred_val = model.predict(X_train_val)\n",
    "print \"F1 score:\", f1_score(y_train_val, y_pred_val)\n",
    "print \"Accuracy score:\", accuracy_score(y_train_val, y_pred_val)\n",
    "plot_confusion_matrix(confusion_matrix(y_true=y_train_val, y_pred=y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=3, class_weight='balanced')\n",
    "clf.fit(X_train_no_val, y_train_no_val)\n",
    "y_pred_val = clf.predict(X_train_val)\n",
    "print \"F1 score:\", f1_score(y_train_val, y_pred_val)\n",
    "print \"Precision Score:\", precision_score(y_train_val, y_pred_val)\n",
    "print \"Recall Score:\", recall_score(y_train_val, y_pred_val)\n",
    "print \"Accuracy score:\", accuracy_score(y_train_val, y_pred_val)\n",
    "plot_confusion_matrix(confusion_matrix(y_true=y_train_val, y_pred=y_pred_val))\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='lbfgs',max_iter=1000,random_state=42,class_weight='balanced')\n",
    "clf.fit(X_train_no_val, y_train_no_val)\n",
    "y_pred_val = clf.predict(X_train_val)\n",
    "print \"F1 score:\", f1_score(y_train_val, y_pred_val)\n",
    "print \"Precision Score:\", precision_score(y_train_val, y_pred_val)\n",
    "print \"Recall Score:\", recall_score(y_train_val, y_pred_val)\n",
    "print \"Accuracy score:\", accuracy_score(y_train_val, y_pred_val)\n",
    "plot_confusion_matrix(confusion_matrix(y_true=y_train_val, y_pred=y_pred_val)) #(clf.predict_proba(X_train_val) >= 0.5).astype(int).sum(axis=1)) #y_pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_class_ratio = float((y_train_no_val==0).sum())/(y_train_no_val==1).sum()\n",
    "clf = xgb.XGBClassifier(scale_pos_weight=balanced_class_ratio, learning_rate=0.05)\n",
    "clf.fit(X_train_no_val, y_train_no_val)\n",
    "y_pred_val = clf.predict(X_train_val)\n",
    "print \"F1 Score:\", f1_score(y_train_val, y_pred_val)\n",
    "print \"Precision Score:\", precision_score(y_train_val, y_pred_val)\n",
    "print \"Recall Score:\", recall_score(y_train_val, y_pred_val)\n",
    "print \"Accuracy Score:\", accuracy_score(y_train_val, y_pred_val)\n",
    "print \"Confusion matrix:\", confusion_matrix(y_true=y_train_val, y_pred=y_pred_val)\n",
    "plot_confusion_matrix(confusion_matrix(y_true=y_train_val,y_pred=y_pred_val))\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save important files to be used for model in web app\n",
    "business_names_str = np.array([ str(name.encode('utf-8')) for name in yelp_businesses_df.name.values ]).astype(str)\n",
    "np.savetxt('VivaLasFoodieRestaurantNames.csv', np.vectorize(lambda x: x.decode('UTF-8'))(business_names_str), delimiter=',', fmt='%s')\n",
    "\n",
    "np.savetxt('chains.csv', np.vectorize(lambda x: x.decode('UTF-8'))(np.array([str(name.encode('utf-8')) for name in chains]).astype(str)),delimiter=',', fmt='%s')\n",
    "\n",
    "np.savetxt('duplicate_locations.csv', duplicate_locations_df.values, delimiter=',')\n",
    "\n",
    "with open('name_to_id_dict.json', 'w') as fp:\n",
    "    json.dump(name_to_id_dict, fp)\n",
    "\n",
    "with open('id_to_features_dict.json', 'w') as fp:\n",
    "    json.dump(id_to_features_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_of_open_businesses_in_city(businesses_df, categories):\n",
    "    open_businesses = []\n",
    "    closed_businesses = []\n",
    "    valid_categories = []\n",
    "    \n",
    "    for category in categories:\n",
    "        category_df = businesses_df[businesses_df['categories'].str.contains(category, na=False)]\n",
    "        num_open = category_df[category_df.is_open == 1].shape[0]\n",
    "        num_closed = category_df[category_df.is_open == 0].shape[0]\n",
    "        if num_open + num_closed > 100 and num_closed > 50:\n",
    "            open_businesses.append(category_df[category_df.is_open == 1].shape[0])\n",
    "            closed_businesses.append(category_df[category_df.is_open == 0].shape[0]) \n",
    "            valid_categories.append(category)\n",
    "        \n",
    "    city_business_distribution = pd.DataFrame(data={'Open' : open_businesses, 'Closed' : closed_businesses}, index=valid_categories)\n",
    "    \n",
    "    return city_business_distribution\n",
    "\n",
    "city_business_distribution = dist_of_open_businesses_in_city(yelp_businesses_df, categories)\n",
    "city_business_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Survival Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = ['is_chain','duplicate_location','cost_2','cost_3','cost_4', 'is_claimed', 'sentiment', 'avg_review_length', \\\n",
    "            'review_count_before_date', 'rating_before_date','age (in days)', 'is_open' ]# + ['city_Las Vegas']#['city_%s'%city for city in cities]\n",
    "data_survival = build_X_and_y(yelp_businesses_df, reviews_df, NOV_14_2018, forecast_months=None, load_NLP=True, ignore_distance=True, do_distance=True, features=features)\n",
    "data_survival_train, data_survival_test = train_test_split(data_survival, test_size=0.2)\n",
    "data_survival_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph = lifelines.CoxPHFitter()\n",
    "cph.fit(data_survival_train.replace(), duration_col='age (in days)', event_col='is_open')\n",
    "cph.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(data_survival_test.is_open.values, cph.predict_survival_function( data_survival_test.drop(['is_open'],axis=1) ).loc[94])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "opt_fpr, opt_tpr, opt_threshold = fpr[(tpr + 1 - fpr).argmax()], tpr[(tpr + 1 - fpr).argmax()], thresholds[(tpr + 1 - fpr).argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='AUC = %0.2f' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.plot([opt_fpr],[opt_tpr],'bo', label='Optimal Threshold' %opt_threshold, markersize=15)\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([-0.01, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve 1-month model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_probs = cph.predict_survival_function(data_survival_test.drop(['is_open'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_length = 94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_roc = np.array([1 if survival_probs.loc[survival_length].iloc[i] > 0.00009 else 0 for i in range(data_survival_test.shape[0]) ])\n",
    "print \"F1 Score:\", f1_score(data_survival_test.is_open.values, y_pred_roc)\n",
    "print \"Precision Score:\", precision_score(data_survival_test.is_open.values, y_pred_roc)\n",
    "print \"Recall Score:\", recall_score(data_survival_test.is_open.values, y_pred_roc)\n",
    "print \"Accuracy Score:\", accuracy_score(data_survival_test.is_open.values, y_pred_roc)\n",
    "plot_confusion_matrix(confusion_matrix(y_true=data_survival_test.is_open.values, y_pred=y_pred_roc))#, title='3 months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
